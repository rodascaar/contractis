# ğŸš€ GuÃ­a RÃ¡pida - Contractis

## Inicio RÃ¡pido

### 1. Compilar el Proyecto
```bash
cd Contractis
go build -o contractis ./cmd
```

### 2. Ejecutar el Servidor
```bash
./contractis
```

O directamente sin compilar:
```bash
go run ./cmd/main.go
```

El servidor estarÃ¡ disponible en: **http://localhost:8080**

### 3. Configurar el LLM

#### OpciÃ³n A: LLM Local (LM Studio)
1. Descargar e instalar [LM Studio](https://lmstudio.ai/)
2. Descargar el modelo Qwen 3 4B o similar
3. Iniciar servidor local (puerto 1234 por defecto)
4. En la interfaz web de Contractis:
   - Tipo: Local
   - URL: `http://localhost:1234/v1/chat/completions`

#### OpciÃ³n B: LLM Online (OpenAI, etc.)
1. Obtener API Key de tu proveedor
2. En la interfaz web de Contractis:
   - Tipo: Online
   - URL: `https://api.openai.com/v1/chat/completions`
   - API Key: tu-api-key
   - Modelo: `gpt-3.5-turbo` o `gpt-4`

### 4. Analizar un Contrato
1. Abrir http://localhost:8080
2. Click en "Seleccionar Archivo"
3. Subir un PDF (mÃ¡ximo 10MB)
4. Click en "ğŸ“Š Estimar Tokens" (opcional pero recomendado)
5. Click en "Analizar Contrato"
6. Esperar el resultado

## ğŸ“ Estructura del Proyecto

```
Contractis/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ main.go                    # Punto de entrada
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ domain/                    # Reglas de negocio
â”‚   â”‚   â”œâ”€â”€ entities/              # Entidades del dominio
â”‚   â”‚   â”œâ”€â”€ repositories/          # Interfaces de repositorios
â”‚   â”‚   â””â”€â”€ services/              # Interfaces de servicios
â”‚   â”œâ”€â”€ usecases/                  # Casos de uso
â”‚   â”‚   â”œâ”€â”€ analyze_contract.go
â”‚   â”‚   â”œâ”€â”€ estimate_tokens.go
â”‚   â”‚   â””â”€â”€ test_llm_connection.go
â”‚   â”œâ”€â”€ infrastructure/            # Implementaciones tÃ©cnicas
â”‚   â”‚   â”œâ”€â”€ pdf/                   # Extractor PDF
â”‚   â”‚   â”œâ”€â”€ llm/                   # Cliente LLM
â”‚   â”‚   â””â”€â”€ text/                  # Procesador de texto
â”‚   â””â”€â”€ adapters/                  # Adaptadores HTTP
â”‚       â””â”€â”€ http/
â”œâ”€â”€ main_old.go                    # CÃ³digo monolÃ­tico original
â”œâ”€â”€ go.mod
â”œâ”€â”€ README.md
â”œâ”€â”€ ARCHITECTURE.md
â””â”€â”€ MIGRATION_GUIDE.md
```

## ğŸ”§ Comandos Ãštiles

### Desarrollo
```bash
# Ejecutar sin compilar
go run ./cmd/main.go

# Compilar
go build -o contractis ./cmd

# Limpiar dependencias
go mod tidy

# Ver dependencias
go list -m all
```

### Testing (cuando se agreguen tests)
```bash
# Ejecutar todos los tests
go test ./...

# Tests con cobertura
go test -cover ./...

# Tests verbose
go test -v ./...
```

### ProducciÃ³n
```bash
# Compilar para producciÃ³n (optimizado)
go build -ldflags="-s -w" -o contractis ./cmd

# Cross-compile para Linux
GOOS=linux GOARCH=amd64 go build -o contractis-linux ./cmd

# Cross-compile para Windows
GOOS=windows GOARCH=amd64 go build -o contractis.exe ./cmd
```

## ğŸ¯ Casos de Uso Principales

### 1. Analizar Contrato
**Endpoint**: `POST /upload`

**ParÃ¡metros**:
- `file`: PDF del contrato
- `llmConfig`: ConfiguraciÃ³n del LLM (JSON)

**Respuesta**:
```json
{
  "success": true,
  "data": "AnÃ¡lisis del contrato..."
}
```

### 2. Estimar Tokens
**Endpoint**: `POST /estimate`

**ParÃ¡metros**:
- `file`: PDF del contrato
- `maxTokens`: MÃ¡ximo de tokens

**Respuesta**:
```json
{
  "success": true,
  "characterCount": 15000,
  "estimatedTokens": 5000,
  "chunks": 5,
  "totalTokens": 12000,
  "recommendedMaxTokens": 1000,
  "warning": ""
}
```

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno (futuro)
Actualmente no se usan, pero puedes agregar:

```bash
# .env
PORT=8080
STATIC_PATH=../static
MAX_FILE_SIZE=10485760  # 10MB
```

### PersonalizaciÃ³n

#### Cambiar Puerto
Editar `cmd/main.go`:
```go
server := httpAdapter.NewServer("3000", appRouter)  // Puerto 3000
```

#### Cambiar Ruta EstÃ¡tica
Editar `cmd/main.go`:
```go
appRouter := router.NewRouter(
    uploadHandler,
    estimateHandler,
    "/ruta/a/static",  // Nueva ruta
)
```

## ğŸ› Troubleshooting

### Error: "No se pudo conectar al LLM"
- Verificar que el servidor LLM estÃ© corriendo
- Verificar la URL del LLM
- Verificar la API Key (si es online)

### Error: "Archivo demasiado grande"
- MÃ¡ximo: 10MB
- Dividir el PDF en partes mÃ¡s pequeÃ±as

### Error: "Solo se permiten archivos PDF"
- Verificar que el archivo tenga extensiÃ³n `.pdf`
- Convertir documentos Word/Excel a PDF primero

### El servidor no inicia
```bash
# Verificar que el puerto 8080 estÃ© libre
lsof -i :8080

# O usar otro puerto
# Editar cmd/main.go y cambiar "8080" por "3000"
```

## ğŸ“Š Rendimiento

### Tiempos Estimados de AnÃ¡lisis

| TamaÃ±o del Documento | Fragmentos | Tiempo Estimado |
|---------------------|------------|-----------------|
| < 5 pÃ¡ginas | 1-2 | 30-60 segundos |
| 5-10 pÃ¡ginas | 3-5 | 1-3 minutos |
| 10-20 pÃ¡ginas | 6-10 | 3-8 minutos |
| 20-50 pÃ¡ginas | 11-20 | 8-20 minutos |
| > 50 pÃ¡ginas | 20+ | 20+ minutos |

**Nota**: Los tiempos dependen del modelo LLM usado y su velocidad.

## ğŸ” Seguridad

### Buenas PrÃ¡cticas
1. **No compartir API Keys**: Nunca subir al repositorio
2. **Validar archivos**: El sistema valida tipo y tamaÃ±o
3. **LÃ­mite de tamaÃ±o**: 10MB mÃ¡ximo
4. **Archivos temporales**: Se eliminan automÃ¡ticamente

### Para ProducciÃ³n
- Agregar autenticaciÃ³n
- Usar HTTPS
- Agregar rate limiting
- Validar origen de requests (CORS mÃ¡s restrictivo)

## ğŸ“š DocumentaciÃ³n Adicional

- [README.md](./README.md) - DocumentaciÃ³n completa
- [ARCHITECTURE.md](./ARCHITECTURE.md) - Detalles de arquitectura
- [MIGRATION_GUIDE.md](./MIGRATION_GUIDE.md) - GuÃ­a de migraciÃ³n

## â“ FAQ

**P: Â¿Puedo usar con otros modelos LLM?**  
R: SÃ­, cualquier modelo compatible con API de OpenAI.

**P: Â¿Funciona offline?**  
R: SÃ­, con un LLM local como LM Studio.

**P: Â¿Puedo analizar contratos en inglÃ©s?**  
R: SÃ­, pero estÃ¡ optimizado para espaÃ±ol.

**P: Â¿Guarda los contratos?**  
R: No, los archivos temporales se eliminan despuÃ©s del anÃ¡lisis.

**P: Â¿CuÃ¡nto cuesta usar con API online?**  
R: Depende del proveedor y tamaÃ±o del documento. Usa la estimaciÃ³n de tokens para calcular.

## ğŸ¤ Soporte

Para reportar bugs o solicitar features, crear un issue en el repositorio.
